# Airflow ETL: Extra√ß√£o e Orquestra√ß√£o de Dados Postais (ViaCEP)

Este projeto demonstra a constru√ß√£o de um pipeline de ETL utilizando o Apache Airflow. O objetivo √© consumir dados p√∫blicos de Endere√ßamento Postal (CEP) do Brasil atrav√©s do webservice ViaCEP.

## ‚öôÔ∏è Arquitetura e Componentes T√©cnicos

A pipeline √© totalmente orquestrada pelo Airflow e utiliza o conceito de Hooks e Operators.

### 1. Custom Hook (`airflow_pipeline/hook/cep_hook.py`)

**`CepHook`**:  Gerencia a conex√£o HTTP com a API ViaCEP e trata erros de API. 

### 2. Custom Operator (`airflow_pipeline/operators/cep_operator.py`)

**`CepOperator`**: Executa a l√≥gica de extra√ß√£o e persist√™ncia dos dados. Utiliza o `CepHook` para coletar dados de +50 CEPs e salva o resultado final em formato CSV. 

### 3. DAG (`dags/extracao_dados_viacep_dag.py`)

A DAG orquestra a execu√ß√£o da tarefa de extra√ß√£o e configura o caminho de sa√≠da no disco.



Entendido. Para quem est√° revisando seu projeto no GitHub, ou para voc√™ mesmo, o que √© mais √∫til √© o passo a passo de como rodar o ETL completo no Airflow, desde o `git clone` at√© a verifica√ß√£o do resultado final.

Aqui est√° o passo a passo completo, do in√≠cio ao fim, focando no terminal e na execu√ß√£o da sua DAG.

## üöÄ Guia R√°pido: Execu√ß√£o Completa do ETL Airflow

Este guia assume que voc√™ j√° tem o Git instalado e o Python 3.8+ configurado.

### 1. Prepara√ß√£o e Configura√ß√£o do Projeto

| Comando | Descri√ß√£o |
| :--- | :--- |
| `git clone https://github.com/gabigam/airflow-viacep-etl.git` | Clona o seu projeto do GitHub. |
| `cd airflow-viacep-etl` | Entra no diret√≥rio raiz do projeto. |
| `python3 -m venv venv` | Cria um ambiente virtual Python. |
| `source venv/bin/activate` | **Ativa** o ambiente virtual (necess√°rio para os comandos `pip` e `airflow`). |
| `pip install -r requirements.txt` | Instala todas as depend√™ncias, incluindo o Airflow. |

### 2. Inicializa√ß√£o do Airflow Standalone

Usaremos o modo *standalone* para inicializar o banco de dados e rodar os componentes essenciais rapidamente.

| Comando | Descri√ß√£o |
| :--- | :--- |
| `airflow standalone` | Inicializa o Airflow (Webserver e Scheduler). O sistema cria a pasta `airflow.cfg` e o banco de dados. |
| *(Ap√≥s a inicializa√ß√£o, pressione `Ctrl + C`)* | Para o Webserver e Scheduler, permitindo rod√°-los separadamente. |

### 3. Rodar Componentes (Em Terminais Separados)

**Importante:** Repita o comando `source venv/bin/activate` em CADA NOVO terminal.

| Terminal 1: Webserver | Terminal 2: Scheduler |
| :--- | :--- |
| `source venv/bin/activate` | `source venv/bin/activate` |
| `airflow webserver --port 8080` | `airflow scheduler` |

### 4. Configura√ß√£o da Conex√£o e Deploy

Com o Webserver rodando (`http://localhost:8080`), voc√™ deve configurar a conex√£o e garantir que as DAGs sejam lidas.

1.  **Deploy dos Arquivos:** O `scheduler` deve reconhecer automaticamente as DAGs e Hooks/Operators, pois eles est√£o no diret√≥rio do Airflow.
2.  **Configurar Conex√£o:**
    * Acesse a UI (`http://localhost:8080`), fa√ßa login (`airflow`/`airflow`).
    * Crie uma **Conex√£o HTTP** com **ID** `viacep_default` e **Host** `https://viacep.com.br`.

### 5. Execu√ß√£o da DAG (O ETL)

1.  Na UI do Airflow, ligue a DAG `extracao_dados_viacep`.
2.  Dispare a DAG manualmente (clique no bot√£o **Play**).
3.  Aguarde o status da tarefa `extracao_ceps_viacep` mudar para **Sucesso (Success)**.

### 6. Verifica√ß√£o do Resultado (O Arquivo CSV)

Verifique se o arquivo CSV com o resultado do seu ETL foi criado no diret√≥rio esperado.

| Comando | Descri√ß√£o |
| :--- | :--- |
| `ls -R datalake/` | Lista o conte√∫do da pasta `datalake` de forma recursiva. |
| `cat datalake/viacep/raw/extract_date=[DATA_HOJE]/ceps_extraidos_[DATA_HOJE].csv` | Exibe o conte√∫do do CSV extra√≠do. |
